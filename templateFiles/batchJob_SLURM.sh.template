#!/bin/bash -login
#SBATCH --kill-on-invalid-dep=yes
#SBATCH --ntasks=?NODES?
#SBATCH --nodes=?NODES?
#SBATCH --cpus-per-task=?PPN?
#SBATCH --time=?HOURS?:?MINUTES?:00
#SBATCH --mem=?MEMORY?G
#SBATCH --job-name=?NAME?
#SBATCH --mail-user=?MAILADDRESS?
#SBATCH --mail-type=?MAILTYPE?
#SBATCH --partition=?QUEUE?
#SBATCH --no-requeue

# load the relevant modules
module load GCCcore/.13.2.0 FFmpeg/.6.0
module load ?MATVERSION?

# change to work dir:
cd ?WORKDIR?

# log file name
LOGFILE=$(echo $SLURM_JOB_ID | cut -d"." -f1).log

# use the Job id as environment variable (to use it inside the Matlab log)
export JOBID=$SLURM_JOB_ID

# Change home directory to avoid file access problems on the Matlab 
# profile directory when trying to open a parallel pool.
# To keep log files in case of crash, use a permanent directory like 
# $BIGWORK/JOBHOMES/$JOBID. Since Matlab R2024b, each job home is ca. 800MB.
# Therefore, the Job Home is created on the /tmp directory and vanishes after job completion.
TMPHOME=$TMPDIR/JOBHOME
mkdir -p $TMPHOME

# run Matlab in endless loop to be able to restart upon error
while true; do
  # back up the job log file (if existing due to previous NODE_FAIL or other error)
  if [[ -f $LOGFILE ]]; then
    LOGFILE_BACKUP="${LOGFILE}_backup_`date '+%Y%m%d_%H%M%S'`"
    mv "$LOGFILE" "$LOGFILE_BACKUP"
    gzip $LOGFILE_BACKUP
  fi
  # show which computer the job ran on and print status information
  echo "Job runs on:" $(hostname) > $LOGFILE
  echo "Working directory:" $(pwd) >> $LOGFILE
  echo "Temporary home directory: $TMPHOME" >> $LOGFILE
  echo "Start time: `date`" >> $LOGFILE
  echo "Run ?MATFILE? using Matlab ?MATVERSION?" >> $LOGFILE
  (export HOME=$TMPHOME && matlab -nodesktop < ?MATFILE? >> $LOGFILE 2>&1)
  echo "Matlab script finished with code $?" >> $LOGFILE
  echo "End: `date`" >> $LOGFILE
  # look into the log and check for filesystem-related reasons for abortion
  # These errors seem not to be able to be catched from within Matlab
  if [[ `grep "fl:filesystem:PathNotFound" $LOGFILE | wc -l` -gt 0 ]]; then
    echo "Error fl:filesystem:PathNotFound seems to have occured. Retry computation" >> $LOGFILE
    sleep 60
    continue
  fi
  # look for other errors, related to the parallel pool
  if [[ `grep "Error in parallel.internal" $LOGFILE | wc -l` -gt 0 ]] || [[ `grep "Error in distcomp.remoteparfor" $LOGFILE | wc -l` -gt 0 ]]; then
    echo "Error within the parallel pool seems to have occured. Retry computation" >> $LOGFILE
    sleep 60
    continue
  fi
  break
done
gzip $LOGFILE
